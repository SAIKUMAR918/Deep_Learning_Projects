{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAIKUMAR918/Deep_Learning_Projects/blob/main/trainable_Vs_NonTrainable_Parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKLx-93_WIaz"
      },
      "source": [
        "# Trainable Vs NonTrainable Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmeOM57lWIa1"
      },
      "source": [
        "In Keras, non-trainable parameters are the ones that are not trained using gradient descent.\n",
        "This is also controlled by the trainable parameter in each layer, for example:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gtAE4u4WIa1"
      },
      "source": [
        "### Model-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A5lRK-iUWIa1",
        "outputId": "bf02fbc1-177c-4aa8-f410-bcbd9f942157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1010 (3.95 KB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1010 (3.95 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "model = Sequential()\n",
        "model.add(Dense(10, trainable=False, input_shape=(100,)))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arfBWqQ2WIa2"
      },
      "source": [
        "Now if you set the layer as trainable with model.layers[0].trainable = True\n",
        "then it prints:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WjI1l1x-WIa3",
        "outputId": "a83a684d-38d8-4a80-a649-cf28b91b95f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1010 (3.95 KB)\n",
            "Trainable params: 1010 (3.95 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.layers[0].trainable = True\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zt7Dl0ZWIa3"
      },
      "source": [
        "### Model-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a_GjytTJWIa3",
        "outputId": "e5d1b154-d38b-4ed0-c33a-e01f04f5c148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1010 (3.95 KB)\n",
            "Trainable params: 1010 (3.95 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10, trainable=True, input_shape=(100,)))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5lq7YLCWIa3"
      },
      "source": [
        "Now all parameters are trainable and there are zero non-trainable parameters. But there are also layers that have both trainable and non-trainable parameters, one example is the BatchNormalization layer, where the mean and standard deviation of the activations is stored for use while test time. One example:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cJjO7j7WIa3"
      },
      "source": [
        "This specific case of BatchNormalization has 40 parameters in total, 20 trainable, and 20 non-trainable. The 20 non-trainable parameters correspond to the computed mean and standard deviation of the activations that is used during test time, and these parameters will never be trainable using gradient descent, and are not affected by the trainable flag.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRyb3rw_WIa3"
      },
      "source": [
        "### Model-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jyGofHu3WIa4",
        "outputId": "6af478f5-94ce-4c5a-f410-1193d9ae7046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 10)                40        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1050 (4.10 KB)\n",
            "Trainable params: 1030 (4.02 KB)\n",
            "Non-trainable params: 20 (80.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.add(BatchNormalization())\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3IytrzqWIa4"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnEQfDJPWIa4"
      },
      "source": [
        "*To sum-up:* 'trainable parameters' are those which value is modified according to their gradient (the derivative of the error/loss/cost relative to the parameter), whereas 'non-trainable parameters' are those which value is not optimized according to their gradient."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}